{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "#from imgaug import augmenters as iaa\n",
    "#import cv2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import keras_metrics\n",
    "from imgaug import augmenters as iaa\n",
    "import tensorflow as tf\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27558, 200, 200, 3), (27558,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = np.load(\"datasets/all/x_all_200.npy\")\n",
    "y_all = np.load(\"datasets/all/y_all_200.npy\")\n",
    "x_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27558, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoded vectors\n",
    "num_classes = 2\n",
    "\n",
    "y_all = np_utils.to_categorical(y_all,num_classes)\n",
    "y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 15,242,050\n",
      "Trainable params: 10,522,434\n",
      "Non-trainable params: 4,719,616\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = x_all.shape[1]\n",
    "\n",
    "def get_model_exp2_b():\n",
    "    base_model = VGG16(weights='imagenet',include_top=False,pooling='avg',input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model.trainable = False\n",
    "    X = base_model.output\n",
    "    X.trainable = False\n",
    "    \n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    predictions = Dense(2, activation='softmax', trainable=True)(X)\n",
    "    \n",
    "    for layer in base_model.layers[-4:]:\n",
    "        layer.trainable=False\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = None\n",
    "model=get_model_exp2_b()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    #model = None\n",
    "    #model=get_model_exp2_b()\n",
    "    #model.summary()\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_all, y_all, test_size=0.10, random_state=42)\n",
    "    \n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    model=get_model_exp2_b()\n",
    "    path_model='vgg_sterioid.h5' \n",
    "\n",
    "\n",
    "    # set the learning rate\n",
    "    K.set_value(model.optimizer.lr, 0.01) \n",
    "\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        rotation_range=35,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        shear_range = 20,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                        steps_per_epoch=len(x_train) / 64, \n",
    "                        epochs=100, \n",
    "                        verbose=1, \n",
    "                        validation_data=(x_val,y_val),\n",
    "                        callbacks=[\n",
    "                           ModelCheckpoint(filepath=path_model, monitor='val_acc',  save_best_only=False),\n",
    "                        ]      \n",
    "                       )\n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "388/387 [==============================] - 376s 970ms/step - loss: 0.2729 - acc: 0.9022 - val_loss: 0.1310 - val_acc: 0.9575\n",
      "Epoch 2/100\n",
      "388/387 [==============================] - 366s 942ms/step - loss: 0.1848 - acc: 0.9340 - val_loss: 0.1122 - val_acc: 0.9608\n",
      "Epoch 3/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.1732 - acc: 0.9377 - val_loss: 0.1038 - val_acc: 0.9637\n",
      "Epoch 4/100\n",
      "388/387 [==============================] - 366s 943ms/step - loss: 0.1635 - acc: 0.9412 - val_loss: 0.1014 - val_acc: 0.9626\n",
      "Epoch 5/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.1545 - acc: 0.9451 - val_loss: 0.0961 - val_acc: 0.9630\n",
      "Epoch 6/100\n",
      "388/387 [==============================] - 368s 949ms/step - loss: 0.1510 - acc: 0.9446 - val_loss: 0.0988 - val_acc: 0.9623\n",
      "Epoch 7/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.1443 - acc: 0.9473 - val_loss: 0.0933 - val_acc: 0.9655\n",
      "Epoch 8/100\n",
      "388/387 [==============================] - 368s 949ms/step - loss: 0.1425 - acc: 0.9479 - val_loss: 0.0923 - val_acc: 0.9666\n",
      "Epoch 9/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.1355 - acc: 0.9509 - val_loss: 0.0896 - val_acc: 0.9673\n",
      "Epoch 10/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.1322 - acc: 0.9522 - val_loss: 0.1045 - val_acc: 0.9619\n",
      "Epoch 11/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.1354 - acc: 0.9510 - val_loss: 0.0879 - val_acc: 0.9663\n",
      "Epoch 12/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.1321 - acc: 0.9516 - val_loss: 0.0959 - val_acc: 0.9677\n",
      "Epoch 13/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.1250 - acc: 0.9551 - val_loss: 0.0915 - val_acc: 0.9663\n",
      "Epoch 14/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.1251 - acc: 0.9546 - val_loss: 0.0856 - val_acc: 0.9677\n",
      "Epoch 15/100\n",
      "388/387 [==============================] - 368s 947ms/step - loss: 0.1215 - acc: 0.9554 - val_loss: 0.0849 - val_acc: 0.9684\n",
      "Epoch 16/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.1204 - acc: 0.9561 - val_loss: 0.0823 - val_acc: 0.9695\n",
      "Epoch 17/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.1210 - acc: 0.9552 - val_loss: 0.0788 - val_acc: 0.9702\n",
      "Epoch 18/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.1155 - acc: 0.9576 - val_loss: 0.0823 - val_acc: 0.9706\n",
      "Epoch 19/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.1172 - acc: 0.9578 - val_loss: 0.0876 - val_acc: 0.9699\n",
      "Epoch 20/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.1143 - acc: 0.9585 - val_loss: 0.0862 - val_acc: 0.9684\n",
      "Epoch 21/100\n",
      "388/387 [==============================] - 369s 952ms/step - loss: 0.1111 - acc: 0.9595 - val_loss: 0.0806 - val_acc: 0.9710\n",
      "Epoch 22/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.1083 - acc: 0.9616 - val_loss: 0.0880 - val_acc: 0.9710\n",
      "Epoch 23/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.1116 - acc: 0.9593 - val_loss: 0.0791 - val_acc: 0.9702\n",
      "Epoch 24/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.1093 - acc: 0.9593 - val_loss: 0.0771 - val_acc: 0.9731\n",
      "Epoch 25/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.1069 - acc: 0.9617 - val_loss: 0.0792 - val_acc: 0.9710\n",
      "Epoch 26/100\n",
      "388/387 [==============================] - 369s 951ms/step - loss: 0.1008 - acc: 0.9634 - val_loss: 0.0783 - val_acc: 0.9735\n",
      "Epoch 27/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.1033 - acc: 0.9617 - val_loss: 0.0793 - val_acc: 0.9710\n",
      "Epoch 28/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.1006 - acc: 0.9622 - val_loss: 0.0820 - val_acc: 0.9706\n",
      "Epoch 29/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.1004 - acc: 0.9624 - val_loss: 0.0764 - val_acc: 0.9735\n",
      "Epoch 30/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.1018 - acc: 0.9625 - val_loss: 0.0792 - val_acc: 0.9717\n",
      "Epoch 31/100\n",
      "388/387 [==============================] - 368s 949ms/step - loss: 0.1014 - acc: 0.9630 - val_loss: 0.0849 - val_acc: 0.9670\n",
      "Epoch 32/100\n",
      "388/387 [==============================] - 369s 950ms/step - loss: 0.0970 - acc: 0.9654 - val_loss: 0.0792 - val_acc: 0.9699\n",
      "Epoch 33/100\n",
      "388/387 [==============================] - 368s 949ms/step - loss: 0.0982 - acc: 0.9634 - val_loss: 0.0809 - val_acc: 0.9713\n",
      "Epoch 34/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0969 - acc: 0.9647 - val_loss: 0.0791 - val_acc: 0.9713\n",
      "Epoch 35/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.0934 - acc: 0.9672 - val_loss: 0.0879 - val_acc: 0.9706\n",
      "Epoch 36/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0947 - acc: 0.9660 - val_loss: 0.0872 - val_acc: 0.9717\n",
      "Epoch 37/100\n",
      "388/387 [==============================] - 368s 947ms/step - loss: 0.0920 - acc: 0.9661 - val_loss: 0.0786 - val_acc: 0.9717\n",
      "Epoch 38/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0933 - acc: 0.9665 - val_loss: 0.0798 - val_acc: 0.9750\n",
      "Epoch 39/100\n",
      "388/387 [==============================] - 368s 950ms/step - loss: 0.0934 - acc: 0.9661 - val_loss: 0.0958 - val_acc: 0.9721\n",
      "Epoch 40/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0883 - acc: 0.9692 - val_loss: 0.0791 - val_acc: 0.9721\n",
      "Epoch 41/100\n",
      "388/387 [==============================] - 369s 952ms/step - loss: 0.0911 - acc: 0.9679 - val_loss: 0.0820 - val_acc: 0.9717\n",
      "Epoch 42/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0886 - acc: 0.9688 - val_loss: 0.0801 - val_acc: 0.9702\n",
      "Epoch 43/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0847 - acc: 0.9681 - val_loss: 0.0946 - val_acc: 0.9710\n",
      "Epoch 44/100\n",
      "388/387 [==============================] - 368s 947ms/step - loss: 0.0865 - acc: 0.9693 - val_loss: 0.0825 - val_acc: 0.9702\n",
      "Epoch 45/100\n",
      "388/387 [==============================] - 368s 949ms/step - loss: 0.0886 - acc: 0.9676 - val_loss: 0.0819 - val_acc: 0.9728\n",
      "Epoch 46/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0846 - acc: 0.9694 - val_loss: 0.0783 - val_acc: 0.9735\n",
      "Epoch 47/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0829 - acc: 0.9699 - val_loss: 0.0809 - val_acc: 0.9735\n",
      "Epoch 48/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.0855 - acc: 0.9698 - val_loss: 0.0857 - val_acc: 0.9724\n",
      "Epoch 49/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.0847 - acc: 0.9701 - val_loss: 0.0906 - val_acc: 0.9713\n",
      "Epoch 50/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0820 - acc: 0.9712 - val_loss: 0.0789 - val_acc: 0.9739\n",
      "Epoch 51/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0812 - acc: 0.9708 - val_loss: 0.0841 - val_acc: 0.9706\n",
      "Epoch 52/100\n",
      "388/387 [==============================] - 368s 949ms/step - loss: 0.0800 - acc: 0.9713 - val_loss: 0.0808 - val_acc: 0.9739\n",
      "Epoch 53/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0806 - acc: 0.9716 - val_loss: 0.0860 - val_acc: 0.9724\n",
      "Epoch 54/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.0785 - acc: 0.9729 - val_loss: 0.0802 - val_acc: 0.9717\n",
      "Epoch 55/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0829 - acc: 0.9704 - val_loss: 0.0856 - val_acc: 0.9692\n",
      "Epoch 56/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0774 - acc: 0.9727 - val_loss: 0.0882 - val_acc: 0.9739\n",
      "Epoch 57/100\n",
      "388/387 [==============================] - 368s 947ms/step - loss: 0.0794 - acc: 0.9716 - val_loss: 0.0825 - val_acc: 0.9728\n",
      "Epoch 58/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0783 - acc: 0.9714 - val_loss: 0.0951 - val_acc: 0.9706\n",
      "Epoch 59/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0773 - acc: 0.9711 - val_loss: 0.0873 - val_acc: 0.9735\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/387 [==============================] - 366s 943ms/step - loss: 0.0799 - acc: 0.9715 - val_loss: 0.0922 - val_acc: 0.9724\n",
      "Epoch 61/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0764 - acc: 0.9721 - val_loss: 0.0840 - val_acc: 0.9735\n",
      "Epoch 62/100\n",
      "388/387 [==============================] - 367s 947ms/step - loss: 0.0755 - acc: 0.9731 - val_loss: 0.0826 - val_acc: 0.9750\n",
      "Epoch 63/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0748 - acc: 0.9740 - val_loss: 0.0890 - val_acc: 0.9742\n",
      "Epoch 64/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0746 - acc: 0.9736 - val_loss: 0.0841 - val_acc: 0.9735\n",
      "Epoch 65/100\n",
      "388/387 [==============================] - 366s 943ms/step - loss: 0.0751 - acc: 0.9735 - val_loss: 0.0821 - val_acc: 0.9753\n",
      "Epoch 66/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0742 - acc: 0.9735 - val_loss: 0.0886 - val_acc: 0.9728\n",
      "Epoch 67/100\n",
      "388/387 [==============================] - 365s 941ms/step - loss: 0.0728 - acc: 0.9739 - val_loss: 0.0883 - val_acc: 0.9724\n",
      "Epoch 68/100\n",
      "388/387 [==============================] - 366s 945ms/step - loss: 0.0710 - acc: 0.9760 - val_loss: 0.0862 - val_acc: 0.9746\n",
      "Epoch 69/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0738 - acc: 0.9723 - val_loss: 0.0835 - val_acc: 0.9750\n",
      "Epoch 70/100\n",
      "388/387 [==============================] - 366s 943ms/step - loss: 0.0712 - acc: 0.9759 - val_loss: 0.0864 - val_acc: 0.9761\n",
      "Epoch 71/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0734 - acc: 0.9741 - val_loss: 0.0885 - val_acc: 0.9753\n",
      "Epoch 72/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0721 - acc: 0.9742 - val_loss: 0.0827 - val_acc: 0.9750\n",
      "Epoch 73/100\n",
      "388/387 [==============================] - 365s 941ms/step - loss: 0.0716 - acc: 0.9745 - val_loss: 0.0848 - val_acc: 0.9713\n",
      "Epoch 74/100\n",
      "388/387 [==============================] - 366s 943ms/step - loss: 0.0709 - acc: 0.9751 - val_loss: 0.0877 - val_acc: 0.9771\n",
      "Epoch 75/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0674 - acc: 0.9760 - val_loss: 0.0967 - val_acc: 0.9713\n",
      "Epoch 76/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0707 - acc: 0.9750 - val_loss: 0.0837 - val_acc: 0.9746\n",
      "Epoch 77/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0689 - acc: 0.9767 - val_loss: 0.1163 - val_acc: 0.9713\n",
      "Epoch 78/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0677 - acc: 0.9760 - val_loss: 0.0847 - val_acc: 0.9750\n",
      "Epoch 79/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0676 - acc: 0.9773 - val_loss: 0.0881 - val_acc: 0.9735\n",
      "Epoch 80/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0639 - acc: 0.9778 - val_loss: 0.0958 - val_acc: 0.9721\n",
      "Epoch 81/100\n",
      "388/387 [==============================] - 365s 940ms/step - loss: 0.0688 - acc: 0.9752 - val_loss: 0.1118 - val_acc: 0.9684\n",
      "Epoch 82/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0662 - acc: 0.9764 - val_loss: 0.0917 - val_acc: 0.9721\n",
      "Epoch 83/100\n",
      "388/387 [==============================] - 365s 941ms/step - loss: 0.0651 - acc: 0.9779 - val_loss: 0.0914 - val_acc: 0.9757\n",
      "Epoch 84/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0654 - acc: 0.9778 - val_loss: 0.1022 - val_acc: 0.9728\n",
      "Epoch 85/100\n",
      "388/387 [==============================] - 366s 942ms/step - loss: 0.0655 - acc: 0.9762 - val_loss: 0.0894 - val_acc: 0.9746\n",
      "Epoch 86/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0668 - acc: 0.9766 - val_loss: 0.1020 - val_acc: 0.9728\n",
      "Epoch 87/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0628 - acc: 0.9776 - val_loss: 0.1082 - val_acc: 0.9706\n",
      "Epoch 88/100\n",
      "388/387 [==============================] - 366s 943ms/step - loss: 0.0643 - acc: 0.9781 - val_loss: 0.0982 - val_acc: 0.9731\n",
      "Epoch 89/100\n",
      "388/387 [==============================] - 368s 948ms/step - loss: 0.0627 - acc: 0.9771 - val_loss: 0.1001 - val_acc: 0.9735\n",
      "Epoch 90/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0616 - acc: 0.9781 - val_loss: 0.0955 - val_acc: 0.9735\n",
      "Epoch 91/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0649 - acc: 0.9768 - val_loss: 0.0935 - val_acc: 0.9746\n",
      "Epoch 92/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0644 - acc: 0.9771 - val_loss: 0.0938 - val_acc: 0.9721\n",
      "Epoch 93/100\n",
      "388/387 [==============================] - 368s 947ms/step - loss: 0.0612 - acc: 0.9797 - val_loss: 0.0967 - val_acc: 0.9742\n",
      "Epoch 94/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0631 - acc: 0.9779 - val_loss: 0.0924 - val_acc: 0.9735\n",
      "Epoch 95/100\n",
      "388/387 [==============================] - 366s 943ms/step - loss: 0.0612 - acc: 0.9783 - val_loss: 0.0971 - val_acc: 0.9731\n",
      "Epoch 96/100\n",
      "388/387 [==============================] - 366s 944ms/step - loss: 0.0595 - acc: 0.9791 - val_loss: 0.0960 - val_acc: 0.9731\n",
      "Epoch 97/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0604 - acc: 0.9788 - val_loss: 0.0915 - val_acc: 0.9731\n",
      "Epoch 98/100\n",
      "388/387 [==============================] - 366s 943ms/step - loss: 0.0607 - acc: 0.9789 - val_loss: 0.1122 - val_acc: 0.9731\n",
      "Epoch 99/100\n",
      "388/387 [==============================] - 367s 945ms/step - loss: 0.0576 - acc: 0.9803 - val_loss: 0.0947 - val_acc: 0.9717\n",
      "Epoch 100/100\n",
      "388/387 [==============================] - 367s 946ms/step - loss: 0.0601 - acc: 0.9787 - val_loss: 0.1044 - val_acc: 0.9724\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-edd88e685fe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcvscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-9acebf38f403>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m                         ]      \n\u001b[0;32m     37\u001b[0m                        )\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "cvscores = []\n",
    "\n",
    "#Define number of split here\n",
    "\n",
    "for x in range(5):\n",
    "    model = train_model()\n",
    "    val_acc = model.history[\"val_acc\"]\n",
    "    cvscores.append(val_acc)\n",
    "    \n",
    "print('Total CV score is {}'.format(np.mean(cvscores)))\n",
    "print('Total CV score std is {}'.format(np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
