{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "#from imgaug import augmenters as iaa\n",
    "#import cv2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_units(y_true, y_pred):\n",
    "    if y_pred.shape[1] != 1:\n",
    "        y_pred = y_pred[:,1:2]\n",
    "        y_true = y_true[:,1:2]\n",
    "    return y_true, y_pred\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22046, 200, 200, 3), (22046, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.load(\"datasets/norm/x_train_norm_200.npy\")\n",
    "y_train = np.load(\"datasets/norm/y_train_norm_200.npy\")\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2756, 200, 200, 3), (2756, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.load(\"datasets/norm/x_val_norm_200.npy\")\n",
    "y_val = np.load(\"datasets/norm/y_val_norm_200.npy\")\n",
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2756, 200, 200, 3), (2756, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.load(\"datasets/norm/x_test_norm_200.npy\")\n",
    "y_test = np.load(\"datasets/norm/y_test_norm_200.npy\")\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = x_train[50]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22046, 200, 200, 3) (22046, 2)\n",
      "(2756, 200, 200, 3) (2756, 200, 200, 3) (2756, 2) (2756, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, x_test.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 200\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 30\n",
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               9437440   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 10,644,770\n",
      "Trainable params: 10,643,810\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = opt,  metrics=['accuracy', precision, recall, f1, matthews_correlation, auc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22046 samples, validate on 2756 samples\n",
      "Epoch 1/20\n",
      "22046/22046 [==============================] - 124s 6ms/step - loss: 0.6947 - acc: 0.7199 - precision: 0.7282 - recall: 0.7194 - f1: 0.7135 - matthews_correlation: 0.4470 - auc: 0.6357 - val_loss: 0.3099 - val_acc: 0.8944 - val_precision: 0.9789 - val_recall: 0.8063 - val_f1: 0.8826 - val_matthews_correlation: 0.8014 - val_auc: 0.8077\n",
      "Epoch 2/20\n",
      "22046/22046 [==============================] - 119s 5ms/step - loss: 0.1949 - acc: 0.9367 - precision: 0.9517 - recall: 0.9224 - f1: 0.9354 - matthews_correlation: 0.8750 - auc: 0.8787 - val_loss: 0.2478 - val_acc: 0.9067 - val_precision: 0.9908 - val_recall: 0.8226 - val_f1: 0.8975 - val_matthews_correlation: 0.8261 - val_auc: 0.9150\n",
      "Epoch 3/20\n",
      "22046/22046 [==============================] - 119s 5ms/step - loss: 0.1607 - acc: 0.9469 - precision: 0.9617 - recall: 0.9329 - f1: 0.9461 - matthews_correlation: 0.8951 - auc: 0.9314 - val_loss: 0.1438 - val_acc: 0.9507 - val_precision: 0.9785 - val_recall: 0.9212 - val_f1: 0.9484 - val_matthews_correlation: 0.9026 - val_auc: 0.9437\n",
      "Epoch 4/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.1453 - acc: 0.9527 - precision: 0.9666 - recall: 0.9390 - f1: 0.9518 - matthews_correlation: 0.9063 - auc: 0.9513 - val_loss: 0.2450 - val_acc: 0.9053 - val_precision: 0.9926 - val_recall: 0.8159 - val_f1: 0.8943 - val_matthews_correlation: 0.8231 - val_auc: 0.9566\n",
      "Epoch 5/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.1357 - acc: 0.9554 - precision: 0.9692 - recall: 0.9415 - f1: 0.9542 - matthews_correlation: 0.9118 - auc: 0.9606 - val_loss: 0.2218 - val_acc: 0.9224 - val_precision: 0.9845 - val_recall: 0.8577 - val_f1: 0.9157 - val_matthews_correlation: 0.8515 - val_auc: 0.9638\n",
      "Epoch 6/20\n",
      "22046/22046 [==============================] - 122s 6ms/step - loss: 0.1276 - acc: 0.9585 - precision: 0.9706 - recall: 0.9462 - f1: 0.9576 - matthews_correlation: 0.9175 - auc: 0.9663 - val_loss: 0.1248 - val_acc: 0.9539 - val_precision: 0.9863 - val_recall: 0.9206 - val_f1: 0.9517 - val_matthews_correlation: 0.9097 - val_auc: 0.9688\n",
      "Epoch 7/20\n",
      "22046/22046 [==============================] - 122s 6ms/step - loss: 0.1210 - acc: 0.9599 - precision: 0.9706 - recall: 0.9492 - f1: 0.9591 - matthews_correlation: 0.9205 - auc: 0.9708 - val_loss: 0.1130 - val_acc: 0.9557 - val_precision: 0.9761 - val_recall: 0.9338 - val_f1: 0.9539 - val_matthews_correlation: 0.9122 - val_auc: 0.9725\n",
      "Epoch 8/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.1131 - acc: 0.9610 - precision: 0.9692 - recall: 0.9525 - f1: 0.9600 - matthews_correlation: 0.9225 - auc: 0.9740 - val_loss: 0.1631 - val_acc: 0.9456 - val_precision: 0.9893 - val_recall: 0.9005 - val_f1: 0.9419 - val_matthews_correlation: 0.8947 - val_auc: 0.9753\n",
      "Epoch 9/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.1074 - acc: 0.9629 - precision: 0.9730 - recall: 0.9527 - f1: 0.9621 - matthews_correlation: 0.9264 - auc: 0.9764 - val_loss: 0.1477 - val_acc: 0.9481 - val_precision: 0.9771 - val_recall: 0.9183 - val_f1: 0.9459 - val_matthews_correlation: 0.8981 - val_auc: 0.9774\n",
      "Epoch 10/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.1063 - acc: 0.9635 - precision: 0.9735 - recall: 0.9535 - f1: 0.9627 - matthews_correlation: 0.9275 - auc: 0.9783 - val_loss: 0.1570 - val_acc: 0.9467 - val_precision: 0.9879 - val_recall: 0.9047 - val_f1: 0.9437 - val_matthews_correlation: 0.8965 - val_auc: 0.9791\n",
      "Epoch 11/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0975 - acc: 0.9652 - precision: 0.9739 - recall: 0.9564 - f1: 0.9645 - matthews_correlation: 0.9307 - auc: 0.9799 - val_loss: 0.1767 - val_acc: 0.9387 - val_precision: 0.9882 - val_recall: 0.8876 - val_f1: 0.9342 - val_matthews_correlation: 0.8818 - val_auc: 0.9805\n",
      "Epoch 12/20\n",
      "22046/22046 [==============================] - 121s 5ms/step - loss: 0.0937 - acc: 0.9657 - precision: 0.9739 - recall: 0.9575 - f1: 0.9650 - matthews_correlation: 0.9318 - auc: 0.9812 - val_loss: 0.1483 - val_acc: 0.9481 - val_precision: 0.9738 - val_recall: 0.9215 - val_f1: 0.9462 - val_matthews_correlation: 0.8975 - val_auc: 0.9818\n",
      "Epoch 13/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0881 - acc: 0.9680 - precision: 0.9748 - recall: 0.9611 - f1: 0.9674 - matthews_correlation: 0.9363 - auc: 0.9823 - val_loss: 0.1176 - val_acc: 0.9604 - val_precision: 0.9734 - val_recall: 0.9457 - val_f1: 0.9588 - val_matthews_correlation: 0.9211 - val_auc: 0.9829\n",
      "Epoch 14/20\n",
      "22046/22046 [==============================] - 119s 5ms/step - loss: 0.0813 - acc: 0.9706 - precision: 0.9777 - recall: 0.9635 - f1: 0.9700 - matthews_correlation: 0.9413 - auc: 0.9834 - val_loss: 0.1291 - val_acc: 0.9594 - val_precision: 0.9839 - val_recall: 0.9347 - val_f1: 0.9582 - val_matthews_correlation: 0.9198 - val_auc: 0.9839\n",
      "Epoch 15/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0789 - acc: 0.9720 - precision: 0.9780 - recall: 0.9660 - f1: 0.9714 - matthews_correlation: 0.9444 - auc: 0.9844 - val_loss: 0.1411 - val_acc: 0.9536 - val_precision: 0.9806 - val_recall: 0.9258 - val_f1: 0.9514 - val_matthews_correlation: 0.9089 - val_auc: 0.9848\n",
      "Epoch 16/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0697 - acc: 0.9739 - precision: 0.9788 - recall: 0.9688 - f1: 0.9733 - matthews_correlation: 0.9479 - auc: 0.9853 - val_loss: 0.1235 - val_acc: 0.9550 - val_precision: 0.9518 - val_recall: 0.9577 - val_f1: 0.9540 - val_matthews_correlation: 0.9104 - val_auc: 0.9857\n",
      "Epoch 17/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0666 - acc: 0.9750 - precision: 0.9792 - recall: 0.9708 - f1: 0.9745 - matthews_correlation: 0.9502 - auc: 0.9861 - val_loss: 0.1479 - val_acc: 0.9597 - val_precision: 0.9771 - val_recall: 0.9402 - val_f1: 0.9578 - val_matthews_correlation: 0.9198 - val_auc: 0.9865\n",
      "Epoch 18/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0601 - acc: 0.9769 - precision: 0.9810 - recall: 0.9730 - f1: 0.9765 - matthews_correlation: 0.9542 - auc: 0.9868 - val_loss: 0.1434 - val_acc: 0.9579 - val_precision: 0.9690 - val_recall: 0.9458 - val_f1: 0.9565 - val_matthews_correlation: 0.9163 - val_auc: 0.9872\n",
      "Epoch 19/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0569 - acc: 0.9783 - precision: 0.9814 - recall: 0.9756 - f1: 0.9780 - matthews_correlation: 0.9569 - auc: 0.9875 - val_loss: 0.1266 - val_acc: 0.9594 - val_precision: 0.9687 - val_recall: 0.9486 - val_f1: 0.9579 - val_matthews_correlation: 0.9187 - val_auc: 0.9878\n",
      "Epoch 20/20\n",
      "22046/22046 [==============================] - 120s 5ms/step - loss: 0.0495 - acc: 0.9816 - precision: 0.9843 - recall: 0.9794 - f1: 0.9814 - matthews_correlation: 0.9635 - auc: 0.9881 - val_loss: 0.1919 - val_acc: 0.9532 - val_precision: 0.9804 - val_recall: 0.9247 - val_f1: 0.9511 - val_matthews_correlation: 0.9077 - val_auc: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f17f94fba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, validation_data = (x_val,y_val), batch_size = BATCH_SIZE, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2756/2756 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16691157183106414,\n",
       " 0.9597242380261248,\n",
       " 0.9813821096032728,\n",
       " 0.9358590107697707,\n",
       " 0.9566889450235186,\n",
       " 0.9203112987025556,\n",
       " 0.9883739669713988]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_3to4(img):\n",
    "    '''\n",
    "    Resizes and expands dimension\n",
    "    \n",
    "    Input: img: a 3-channel image as input\n",
    "    \n",
    "    Returns a rank-4 tensor, since the network accepts batches of images\n",
    "    One image corresponds to batch size of 1\n",
    "    '''\n",
    "    img = cv2.resize(img, (200, 200))\n",
    "    img_4d = np.expand_dims(img, axis=0)  # rank 4 tensor for prediction\n",
    "    return img_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x1f040c5b4e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f040c5b710>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f040c4cc88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1f040c5be48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f040c7d240>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f040c7d908>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f17ea79f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1f040cfd940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f17ea79828>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f17ea49320>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f17ebc0748>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1f17eb4a7b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f17ebc0b70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f17eb98898>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f17ed05c50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1f17ecbf3c8>,\n",
       " <keras.layers.core.Flatten at 0x1f17ed05940>,\n",
       " <keras.layers.core.Dense at 0x1f17ecd0f28>,\n",
       " <keras.layers.core.Dropout at 0x1f17ed29128>,\n",
       " <keras.layers.core.Dense at 0x1f17ed6ba58>,\n",
       " <keras.layers.core.Dropout at 0x1f17ed6bb38>,\n",
       " <keras.layers.core.Dense at 0x1f17ee50f28>,\n",
       " <keras.layers.core.Activation at 0x1f17ee7bba8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               9437440   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 10,644,512\n",
      "Trainable params: 10,643,552\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "layer_name = 'dense_2'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = []\n",
    "for x in x_train:\n",
    "    x = tensor_3to4(x)\n",
    "    intermediate_output = intermediate_layer_model.predict(x)\n",
    "    x_features.append(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22046"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features[55].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = np.array(x_features)\n",
    "nsamples, nx, ny = x_features.shape\n",
    "d2_train_dataset = x_features.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC( probability=True, gamma=.1)\n",
    "cv_score = cross_val_score(classifier, d2_train_dataset, y_train[:,1:2], cv=5, scoring='roc_auc')\n",
    "results.append(cv_score)\n",
    "classifier.fit(d2_train_dataset, y_train[:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99474677, 0.99720504, 0.99609755, 0.99724555, 0.99758706])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "for y in x_test:\n",
    "    y = tensor_3to4(y)\n",
    "    intermediate_output = intermediate_layer_model.predict(y)\n",
    "    test_features.append(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.array(test_features)\n",
    "nsamples, nx, ny = test_features.shape\n",
    "d2_test_dataset = test_features.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(d2_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9328737300435413"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,1:2], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.89      0.93      1409\n",
      "         1.0       0.89      0.98      0.93      1347\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2756\n",
      "   macro avg       0.94      0.93      0.93      2756\n",
      "weighted avg       0.94      0.93      0.93      2756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,1:2], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696471776399957"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_test[:,1:2], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
