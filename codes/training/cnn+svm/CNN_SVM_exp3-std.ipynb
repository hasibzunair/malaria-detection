{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import CSVLogger\n",
    "#from livelossplot import PlotLossesKeras\n",
    "import os\n",
    "import numpy as np\n",
    "#from imgaug import augmenters as iaa\n",
    "#import cv2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from keras import initializers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_units(y_true, y_pred):\n",
    "    if y_pred.shape[1] != 1:\n",
    "        y_pred = y_pred[:,1:2]\n",
    "        y_true = y_true[:,1:2]\n",
    "    return y_true, y_pred\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def matthews_correlation(y_true, y_pred):\n",
    "    y_true, y_pred = check_units(y_true, y_pred)\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22046, 200, 200, 3), (22046, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.load(\"datasets/std/x_train_std_200.npy\")\n",
    "y_train = np.load(\"datasets/std/y_train_std_200.npy\")\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2756, 200, 200, 3), (2756, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.load(\"datasets/std/x_val_std_200.npy\")\n",
    "y_val = np.load(\"datasets/std/y_val_std_200.npy\")\n",
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2756, 200, 200, 3), (2756, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.load(\"datasets/std/x_test_std_200.npy\")\n",
    "y_test = np.load(\"datasets/std/y_test_std_200.npy\")\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = x_train[50]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22046, 200, 200, 3) (22046, 2)\n",
      "(2756, 200, 200, 3) (2756, 200, 200, 3) (2756, 2) (2756, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, x_test.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 200\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 30\n",
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape, activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               9437440   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 10,644,770\n",
      "Trainable params: 10,643,810\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = opt,  metrics=['accuracy', precision, recall, f1, matthews_correlation, auc])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22046 samples, validate on 2756 samples\n",
      "Epoch 1/20\n",
      "22046/22046 [==============================] - 136s 6ms/step - loss: 0.3917 - acc: 0.8923 - precision: 0.9162 - recall: 0.8698 - f1: 0.8881 - matthews_correlation: 0.7893 - auc: 0.8803 - val_loss: 0.1827 - val_acc: 0.9307 - val_precision: 0.9866 - val_recall: 0.8735 - val_f1: 0.9258 - val_matthews_correlation: 0.8667 - val_auc: 0.9470\n",
      "Epoch 2/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1929 - acc: 0.9391 - precision: 0.9630 - recall: 0.9150 - f1: 0.9371 - matthews_correlation: 0.8802 - auc: 0.9579 - val_loss: 0.1578 - val_acc: 0.9358 - val_precision: 0.9874 - val_recall: 0.8843 - val_f1: 0.9321 - val_matthews_correlation: 0.8763 - val_auc: 0.9641\n",
      "Epoch 3/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1659 - acc: 0.9463 - precision: 0.9669 - recall: 0.9262 - f1: 0.9451 - matthews_correlation: 0.8942 - auc: 0.9680 - val_loss: 0.1445 - val_acc: 0.9445 - val_precision: 0.9868 - val_recall: 0.9017 - val_f1: 0.9415 - val_matthews_correlation: 0.8921 - val_auc: 0.9709\n",
      "Epoch 4/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1471 - acc: 0.9506 - precision: 0.9668 - recall: 0.9345 - f1: 0.9495 - matthews_correlation: 0.9021 - auc: 0.9732 - val_loss: 0.1487 - val_acc: 0.9474 - val_precision: 0.9859 - val_recall: 0.9082 - val_f1: 0.9447 - val_matthews_correlation: 0.8975 - val_auc: 0.9749\n",
      "Epoch 5/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1385 - acc: 0.9536 - precision: 0.9704 - recall: 0.9363 - f1: 0.9522 - matthews_correlation: 0.9081 - auc: 0.9764 - val_loss: 0.1343 - val_acc: 0.9503 - val_precision: 0.9837 - val_recall: 0.9159 - val_f1: 0.9479 - val_matthews_correlation: 0.9024 - val_auc: 0.9775\n",
      "Epoch 6/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1291 - acc: 0.9567 - precision: 0.9706 - recall: 0.9424 - f1: 0.9556 - matthews_correlation: 0.9140 - auc: 0.9786 - val_loss: 0.1309 - val_acc: 0.9507 - val_precision: 0.9825 - val_recall: 0.9176 - val_f1: 0.9482 - val_matthews_correlation: 0.9031 - val_auc: 0.9796\n",
      "Epoch 7/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1236 - acc: 0.9582 - precision: 0.9727 - recall: 0.9434 - f1: 0.9571 - matthews_correlation: 0.9172 - auc: 0.9804 - val_loss: 0.1245 - val_acc: 0.9539 - val_precision: 0.9836 - val_recall: 0.9236 - val_f1: 0.9521 - val_matthews_correlation: 0.9092 - val_auc: 0.9812\n",
      "Epoch 8/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1154 - acc: 0.9595 - precision: 0.9696 - recall: 0.9493 - f1: 0.9587 - matthews_correlation: 0.9194 - auc: 0.9819 - val_loss: 0.1406 - val_acc: 0.9488 - val_precision: 0.9855 - val_recall: 0.9105 - val_f1: 0.9459 - val_matthews_correlation: 0.8998 - val_auc: 0.9825\n",
      "Epoch 9/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1078 - acc: 0.9627 - precision: 0.9738 - recall: 0.9513 - f1: 0.9618 - matthews_correlation: 0.9258 - auc: 0.9831 - val_loss: 0.1653 - val_acc: 0.9474 - val_precision: 0.9432 - val_recall: 0.9514 - val_f1: 0.9465 - val_matthews_correlation: 0.8948 - val_auc: 0.9836\n",
      "Epoch 10/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.1064 - acc: 0.9637 - precision: 0.9743 - recall: 0.9535 - f1: 0.9630 - matthews_correlation: 0.9279 - auc: 0.9840 - val_loss: 0.1404 - val_acc: 0.9532 - val_precision: 0.9858 - val_recall: 0.9200 - val_f1: 0.9510 - val_matthews_correlation: 0.9085 - val_auc: 0.9845\n",
      "Epoch 11/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0964 - acc: 0.9653 - precision: 0.9749 - recall: 0.9558 - f1: 0.9647 - matthews_correlation: 0.9309 - auc: 0.9849 - val_loss: 0.1268 - val_acc: 0.9568 - val_precision: 0.9825 - val_recall: 0.9297 - val_f1: 0.9547 - val_matthews_correlation: 0.9149 - val_auc: 0.9853\n",
      "Epoch 12/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0930 - acc: 0.9667 - precision: 0.9749 - recall: 0.9582 - f1: 0.9660 - matthews_correlation: 0.9338 - auc: 0.9858 - val_loss: 0.2011 - val_acc: 0.9358 - val_precision: 0.9158 - val_recall: 0.9604 - val_f1: 0.9366 - val_matthews_correlation: 0.8725 - val_auc: 0.9861\n",
      "Epoch 13/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0879 - acc: 0.9687 - precision: 0.9761 - recall: 0.9610 - f1: 0.9679 - matthews_correlation: 0.9377 - auc: 0.9864 - val_loss: 0.1178 - val_acc: 0.9579 - val_precision: 0.9706 - val_recall: 0.9435 - val_f1: 0.9564 - val_matthews_correlation: 0.9158 - val_auc: 0.9867\n",
      "Epoch 14/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0831 - acc: 0.9699 - precision: 0.9775 - recall: 0.9623 - f1: 0.9693 - matthews_correlation: 0.9401 - auc: 0.9871 - val_loss: 0.1293 - val_acc: 0.9539 - val_precision: 0.9764 - val_recall: 0.9297 - val_f1: 0.9518 - val_matthews_correlation: 0.9088 - val_auc: 0.9874\n",
      "Epoch 15/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0784 - acc: 0.9703 - precision: 0.9763 - recall: 0.9643 - f1: 0.9697 - matthews_correlation: 0.9409 - auc: 0.9877 - val_loss: 0.1188 - val_acc: 0.9601 - val_precision: 0.9594 - val_recall: 0.9600 - val_f1: 0.9591 - val_matthews_correlation: 0.9202 - val_auc: 0.9880\n",
      "Epoch 16/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0699 - acc: 0.9739 - precision: 0.9782 - recall: 0.9695 - f1: 0.9733 - matthews_correlation: 0.9480 - auc: 0.9883 - val_loss: 0.1134 - val_acc: 0.9612 - val_precision: 0.9748 - val_recall: 0.9465 - val_f1: 0.9598 - val_matthews_correlation: 0.9228 - val_auc: 0.9886\n",
      "Epoch 17/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0666 - acc: 0.9763 - precision: 0.9812 - recall: 0.9714 - f1: 0.9758 - matthews_correlation: 0.9527 - auc: 0.9889 - val_loss: 0.1311 - val_acc: 0.9579 - val_precision: 0.9743 - val_recall: 0.9404 - val_f1: 0.9564 - val_matthews_correlation: 0.9160 - val_auc: 0.9891\n",
      "Epoch 18/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0584 - acc: 0.9786 - precision: 0.9830 - recall: 0.9740 - f1: 0.9781 - matthews_correlation: 0.9573 - auc: 0.9894 - val_loss: 0.1479 - val_acc: 0.9554 - val_precision: 0.9725 - val_recall: 0.9375 - val_f1: 0.9541 - val_matthews_correlation: 0.9111 - val_auc: 0.9896\n",
      "Epoch 19/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0561 - acc: 0.9799 - precision: 0.9823 - recall: 0.9775 - f1: 0.9794 - matthews_correlation: 0.9599 - auc: 0.9898 - val_loss: 0.1703 - val_acc: 0.9536 - val_precision: 0.9742 - val_recall: 0.9310 - val_f1: 0.9514 - val_matthews_correlation: 0.9078 - val_auc: 0.9900\n",
      "Epoch 20/20\n",
      "22046/22046 [==============================] - 131s 6ms/step - loss: 0.0473 - acc: 0.9819 - precision: 0.9847 - recall: 0.9792 - f1: 0.9815 - matthews_correlation: 0.9641 - auc: 0.9903 - val_loss: 0.1580 - val_acc: 0.9561 - val_precision: 0.9760 - val_recall: 0.9351 - val_f1: 0.9543 - val_matthews_correlation: 0.9131 - val_auc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263ff9af748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, validation_data = (x_val,y_val), batch_size = BATCH_SIZE, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2756/2756 [==============================] - 8s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1431749242113801,\n",
       " 0.9637155297532656,\n",
       " 0.9727437677854032,\n",
       " 0.9529314330077483,\n",
       " 0.9615423431071211,\n",
       " 0.9277156786925561,\n",
       " 0.9904584864746503]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_3to4(img):\n",
    "    '''\n",
    "    Resizes and expands dimension\n",
    "    \n",
    "    Input: img: a 3-channel image as input\n",
    "    \n",
    "    Returns a rank-4 tensor, since the network accepts batches of images\n",
    "    One image corresponds to batch size of 1\n",
    "    '''\n",
    "    img = cv2.resize(img, (200, 200))\n",
    "    img_4d = np.expand_dims(img, axis=0)  # rank 4 tensor for prediction\n",
    "    return img_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x263ffa0b160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x263ffa0b390>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x263ffa00978>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x263ffa0bac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x263ffa0b860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x263ffa00a20>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x26b12673860>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26b125f1748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26b12698860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26b126983c8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x26b127d5d68>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26b126f0d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26b127d5588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x26b127d5b00>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x26b1291cfd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x26b128a5f98>,\n",
       " <keras.layers.core.Flatten at 0x26b1291c588>,\n",
       " <keras.layers.core.Dense at 0x26b128d1f60>,\n",
       " <keras.layers.core.Dropout at 0x26b12947b00>,\n",
       " <keras.layers.core.Dense at 0x26b1295fc88>,\n",
       " <keras.layers.core.Dropout at 0x26b1295f5c0>,\n",
       " <keras.layers.core.Dense at 0x26b12a660b8>,\n",
       " <keras.layers.core.Activation at 0x26b12a96828>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 25, 25, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               9437440   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "=================================================================\n",
      "Total params: 10,644,512\n",
      "Trainable params: 10,643,552\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "layer_name = 'dense_2'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = []\n",
    "for x in x_train:\n",
    "    x = tensor_3to4(x)\n",
    "    intermediate_output = intermediate_layer_model.predict(x)\n",
    "    x_features.append(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22046"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features[55].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = np.array(x_features)\n",
    "nsamples, nx, ny = x_features.shape\n",
    "d2_train_dataset = x_features.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\malaria\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC( probability=True, gamma=.1)\n",
    "cv_score = cross_val_score(classifier, d2_train_dataset, y_train[:,1:2], cv=5, scoring='roc_auc')\n",
    "results.append(cv_score)\n",
    "classifier.fit(d2_train_dataset, y_train[:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99809686, 0.99817481, 0.99777932, 0.99855055, 0.99906393])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "for y in x_test:\n",
    "    y = tensor_3to4(y)\n",
    "    intermediate_output = intermediate_layer_model.predict(y)\n",
    "    test_features.append(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.array(test_features)\n",
    "nsamples, nx, ny = test_features.shape\n",
    "d2_test_dataset = test_features.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(d2_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9241654571843251"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,1:2], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.87      0.92      1409\n",
      "         1.0       0.88      0.98      0.93      1347\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      2756\n",
      "   macro avg       0.93      0.93      0.92      2756\n",
      "weighted avg       0.93      0.92      0.92      2756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,1:2], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547848716915234"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_test[:,1:2], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
